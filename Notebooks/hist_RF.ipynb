{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./utils/\")\n",
    "import random\n",
    "from data_path import *\n",
    "from glob import glob\n",
    "from os.path import join, basename, dirname, samefile\n",
    "from tqdm import tqdm\n",
    "from skimage import data, color, exposure \n",
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "import re\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 334363/334363 [47:50<00:00, 116.50it/s]\n"
     ]
    }
   ],
   "source": [
    "X = list()\n",
    "Y = list()\n",
    "files = get_all_files(cropped=True)\n",
    "for file in tqdm(files):\n",
    "    image = imread(file)\n",
    "    image = color.rgb2hsv(image) # представляем изображение как трехмерный массив [x,y,3], вместо 3 слоев rgb - hue, saturation и v\n",
    "    #используем только hue, так как в соло оно показательно\n",
    "    fd = exposure.histogram(image[:,:,0])[0]\n",
    "    X.append(fd)\n",
    "    Y.append(get_genre_id(file))\n",
    "X = np.asarray(X)\n",
    "Y = np.asarray(Y)\n",
    "np.save(join(FEATURES[\"RF\"],'X_hist'),X)\n",
    "np.save(join(FEATURES[\"RF\"],'Y'),Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files_cropped = get_all_files(cropped=True)\n",
    "files_origin = get_all_files(cropped=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.load(join(FEATURES[\"RF\"],'X_hist.npy'))\n",
    "Y = np.load(join(FEATURES[\"RF\"],'Y.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.22244054,  0.22578417,  0.2228573 ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=50)\n",
    "cross_val_score(classifier, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uncut_files = {(dirname(f),re.sub(\"[0-9]+_[0-9]+_\",\"\",basename(f))) for f in files_cropped}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RF_train_files = set(random.sample(uncut_files,9000))\n",
    "RF_test_files = uncut_files.difference(RF_train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "334363it [00:04, 81379.11it/s]\n"
     ]
    }
   ],
   "source": [
    "files_cropped_dict = dict()\n",
    "for i,f in tqdm(enumerate(files_cropped)):\n",
    "    directory = dirname(f)\n",
    "    name_origin = re.sub(\"[0-9]+_[0-9]+_\",\"\",basename(f))\n",
    "    try:\n",
    "        files_cropped_dict[(directory, name_origin)].append(i)\n",
    "    except KeyError:\n",
    "        files_cropped_dict[(directory, name_origin)] = [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RF_train_indices = list()\n",
    "for f in RF_train_files:\n",
    "    RF_train_indices.extend(files_cropped_dict[f])\n",
    "RF_train_indices = np.asarray(RF_train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_RF = X[RF_train_indices]\n",
    "Y_train_RF = Y[RF_train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = np.ones((X.shape[0])).astype(bool)\n",
    "mask[RF_train_indices] = False\n",
    "X_test_RF = X[mask]\n",
    "Y_test_RF = Y[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train_RF,Y_train_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 9037/9037 [00:08<00:00, 1038.75it/s]\n"
     ]
    }
   ],
   "source": [
    "X_RF_NN = list()\n",
    "Y_RF_NN = list()\n",
    "for f in tqdm(RF_test_files):\n",
    "    indices = files_cropped_dict[f]\n",
    "    ys = classifier.predict(X[indices])\n",
    "    ans = np.zeros((150, 18)).astype(int)\n",
    "    i = 0\n",
    "    for y in ys:\n",
    "        ans[i][y-1] = 1\n",
    "        i += 1\n",
    "        if i >= 150:\n",
    "            break\n",
    "    X_RF_NN.append(ans.flatten())\n",
    "    Y_RF_NN.append(Y[indices][0])\n",
    "X_RF_NN = np.asarray(X_RF_NN)\n",
    "Y_RF_NN = np.asarray(Y_RF_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9037,)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.save(\"X_RF_NN\",)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
