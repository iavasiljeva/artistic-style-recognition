{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./utils/\")\n",
    "import random\n",
    "from data_path import *\n",
    "from glob import glob\n",
    "from os.path import join, basename, dirname, samefile\n",
    "from tqdm import tqdm\n",
    "from skimage import data, color, exposure \n",
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from scipy.io import loadmat\n",
    "import re\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat = loadmat('../Features/padoraPHoT.mat')\n",
    "main = loadmat('../pandora18kMain_v2.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_hot = mat['data'][:18000]\n",
    "Y_hot = mat['imgLabel'][:18000].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(join(FEATURES['RF_HoT'], \"X_hot_NN\"), X_hot)\n",
    "np.save(join(FEATURES['RF_HoT'], \"Y_hot_NN\"), Y_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "main_file_names = ['..\\\\Pandora_18k\\\\CROP\\\\' + f[0][0][0][0][0] for f in main['imageListFile'][:18000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 334363/334363 [47:50<00:00, 116.50it/s]\n"
     ]
    }
   ],
   "source": [
    "X = list()\n",
    "Y = list()\n",
    "files = get_all_files(cropped=True)\n",
    "for file in tqdm(files):\n",
    "    image = imread(file)\n",
    "    image = color.rgb2hsv(image)\n",
    "    fd = exposure.histogram(image[:,:,0])[0]\n",
    "    X.append(fd)\n",
    "    Y.append(get_genre_id(file))\n",
    "X = np.asarray(X)\n",
    "Y = np.asarray(Y)\n",
    "np.save(join(FEATURES[\"RF\"],'X_hist'),X)\n",
    "np.save(join(FEATURES[\"RF\"],'Y'),Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files_cropped = get_all_files(cropped=True)\n",
    "# files_origin = get_all_files(cropped=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.load(join(FEATURES[\"RF\"],'X_hist.npy'))\n",
    "Y = np.load(join(FEATURES[\"RF\"],'Y.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "334363it [00:04, 78983.64it/s]\n"
     ]
    }
   ],
   "source": [
    "files_cropped_dict = dict()\n",
    "for i,f in tqdm(enumerate(files_cropped)):\n",
    "    directory = dirname(f)\n",
    "    name_origin = re.sub(\"[0-9]+_[0-9]+_\",\"\",basename(f))\n",
    "    try:\n",
    "        files_cropped_dict[(directory, name_origin)].append(i)\n",
    "    except KeyError:\n",
    "        files_cropped_dict[(directory, name_origin)] = [i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(47, 17953)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncut_files = {(dirname(f),basename(f)) for f in main_file_names}\n",
    "print(len(uncut_files))\n",
    "to_remove = set()\n",
    "for el in uncut_files:\n",
    "    if el not in files_cropped_dict:\n",
    "        to_remove.add(el)\n",
    "uncut_files = uncut_files.difference(to_remove)\n",
    "len(to_remove), len(uncut_files)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RF_train_files = set(random.sample(uncut_files,9000))\n",
    "RF_test_files = uncut_files.difference(RF_train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RF_train_indices = list()\n",
    "for f in RF_train_files:\n",
    "    RF_train_indices.extend(files_cropped_dict[f])\n",
    "RF_train_indices = np.asarray(RF_train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_RF = X[RF_train_indices]\n",
    "Y_train_RF = Y[RF_train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RF_test_indices = list()\n",
    "RF_test_files = sorted(RF_test_files)\n",
    "for f in RF_test_files:\n",
    "    RF_test_indices.extend(files_cropped_dict[f])\n",
    "RF_test_indices = np.asarray(RF_test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_RF = X[RF_test_indices]\n",
    "Y_test_RF = Y[RF_test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save(join(FEATURES[\"RF_HoT\"],'X_train_RF'),X_train_RF)\n",
    "np.save(join(FEATURES[\"RF_HoT\"],'Y_train_RF'),Y_train_RF)\n",
    "np.save(join(FEATURES[\"RF_HoT\"],'X_test_RF'),X_test_RF)\n",
    "np.save(join(FEATURES[\"RF_HoT\"],'Y_test_RF'),Y_test_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_RF = np.load(join(FEATURES[\"RF_HoT\"],'X_train_RF.npy'))\n",
    "Y_train_RF = np.load(join(FEATURES[\"RF_HoT\"],'Y_train_RF.npy'))\n",
    "X_test_RF = np.load(join(FEATURES[\"RF_HoT\"],'X_test_RF.npy'))\n",
    "Y_test_RF = np.load(join(FEATURES[\"RF_HoT\"],'Y_test_RF.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=100 )\n",
    "classifier.fit(X_train_RF,Y_train_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(classifier, open(join(FEATURES[\"RF_HoT\"],'RF_classifier'), 'wb'))\n",
    "pickle.dump(RF_test_files, open(join(FEATURES[\"RF_HoT\"],'RF_test_files'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "classifier = pickle.load( open(join(FEATURES[\"RF_HoT\"],'RF_classifier'), 'rb'))\n",
    "RF_test_files = pickle.load(open(join(FEATURES[\"RF_HoT\"],'RF_test_files'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_RF = np.load(join(FEATURES[\"RF_HoT\"],'X_test_RF.npy'))\n",
    "Y_test_RF = np.load(join(FEATURES[\"RF_HoT\"],'Y_test_RF.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RF_test_files = np.load(join(FEATURES[\"RF_HoT\"],'RF_test_files.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 8953/8953 [01:11<00:00, 124.88it/s]\n"
     ]
    }
   ],
   "source": [
    "X_RF_NN = list()\n",
    "X_hot_NN = list()\n",
    "Y_RF_NN = list()\n",
    "Y_hot_NN = list()\n",
    "for f in tqdm(RF_test_files):\n",
    "    hot_index = main_file_names.index(join(f[0], f[1]))\n",
    "    X_hot_NN.append(X_hot[hot_index])\n",
    "    Y_hot_NN.append(Y_hot[hot_index])\n",
    "    indices = files_cropped_dict[f]\n",
    "    ys = classifier.predict(X[indices])\n",
    "    ans = np.zeros((150, 18)).astype(int)\n",
    "    i = 0\n",
    "    for y in ys:\n",
    "        ans[i][y-1] = 1\n",
    "        i += 1\n",
    "        if i >= 150:\n",
    "            break\n",
    "    X_RF_NN.append(ans.flatten())\n",
    "    Y_RF_NN.append(Y[indices][0])\n",
    "X_RF_NN = np.asarray(X_RF_NN)\n",
    "Y_RF_NN = np.asarray(Y_RF_NN)\n",
    "X_hot_NN = np.asarray(X_hot_NN)\n",
    "Y_hot_NN = np.asarray(Y_hot_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_RF_hot_NN = np.concatenate([X_RF_NN, X_hot_NN], axis=1)\n",
    "Y_RF_hot_NN = Y_RF_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.save(join(FEATURES['RF_HoT'], \"X_RF_hot_NN_2\"), X_RF_hot_NN)\n",
    "np.save(join(FEATURES['RF_HoT'], \"Y_RF_hot_NN_2\"), Y_RF_hot_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
